{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e46479ce",
   "metadata": {},
   "source": [
    "## Capstone Project - RSNA Pneumonia Detection Challenge\n",
    "**Problem Statement**\n",
    "\n",
    "In this capstone project, the goal is to build a pneumonia detection system, to locate the position of inflammation in an image. Tissues with sparse material, such as lungs which are full of air, do not absorb the X-rays and appear black in the image. Dense tissues such as bones absorb X-rays and appear white in the image. While we are theoretically detecting “lung opacities”, there are lung opacities that are not pneumonia related. In the data, some of these are labeled “Not Normal No Lung Opacity”. This extra third class indicates that while pneumonia was determined not to be present, there was nonetheless some type of abnormality on the image and oftentimes this finding may mimic the appearance of true pneumonia.\n",
    "\n",
    "**Dicom original images**: Medical images are stored in a special format called DICOM files (*.dcm). They contain a combination of header metadata as well as underlying raw image arrays for pixel data.\n",
    "\n",
    "**Here’s the backstory and why solving this problem matters**\n",
    "\n",
    "**Pneumonia accounts for over 15% of all deaths of children under 5 years old internationally.** In 2015, 920,000 children under the age of 5 died from the disease. In the United States, pneumonia accounts for over 500,000 visits to emergency departments and over 50,000 deaths in 2015, keeping the ailment on the list of top 10 causes of death in the country.\n",
    "\n",
    "While common, accurately diagnosing pneumonia is a tall order. It requires review of a **chest radiograph (CXR)** by **highly trained specialists** and confirmation through clinical history, vital signs and laboratory exams. Pneumonia usually manifests as an area or areas of increased opacity on CXR. However, the **diagnosis of pneumonia on CXR is complicated** because of a number of other conditions in the lungs such as fluid overload (pulmonary edema), bleeding, volume loss (atelectasis or collapse), lung cancer, or post-radiation or surgical changes. Outside of the lungs, fluid in the pleural space (pleural effusion) also appears as increased opacity on CXR. When available, comparison of CXRs of the patient taken at different time points and correlation with clinical symptoms and history are helpful in making the diagnosis.\n",
    "\n",
    "CXRs are the most commonly performed diagnostic imaging study. **A number of factors such as positioning of the patient and depth of inspiration can alter the appearance of the CXR, complicating interpretation further. In addition, clinicians are faced with reading high volumes of images every shift.**\n",
    "\n",
    "\n",
    "To improve the efficiency and reach of diagnostic services, the Radiological Society of North America (RSNA®) has reached out to Kaggle’s machine learning community and collaborated with the US National Institutes of Health, The Society of Thoracic Radiology, and MD.ai to develop a rich dataset for this challenge. ([Description Source](https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/overview/description))\n",
    "\n",
    "**Data Source**: https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe8c665",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "043d1bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydicom in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (2.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing requirements for matplotlib: [Errno 2] No such file or directory: 'c:\\\\users\\\\sagar\\\\anaconda3\\\\envs\\\\tensorflow-gpu\\\\lib\\\\site-packages\\\\matplotlib-3.4.3.dist-info\\\\METADATA'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (4.5.3.56)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from opencv-python) (1.19.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing requirements for matplotlib: [Errno 2] No such file or directory: 'c:\\\\users\\\\sagar\\\\anaconda3\\\\envs\\\\tensorflow-gpu\\\\lib\\\\site-packages\\\\matplotlib-3.4.3.dist-info\\\\METADATA'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: clang~=5.0 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow) (5.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow) (1.38.1)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow) (0.13.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow) (3.17.3)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-estimator~=2.6 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: keras~=2.6 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: cached-property in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.32.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.5.30)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from werkzeug>=0.11.15->tensorboard~=2.6->tensorflow) (0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\sagar\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.4.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing requirements for matplotlib: [Errno 2] No such file or directory: 'c:\\\\users\\\\sagar\\\\anaconda3\\\\envs\\\\tensorflow-gpu\\\\lib\\\\site-packages\\\\matplotlib-3.4.3.dist-info\\\\METADATA'\n"
     ]
    }
   ],
   "source": [
    "# Install packages\n",
    "import sys\n",
    "!{sys.executable} -m pip install pydicom\n",
    "!{sys.executable} -m pip install opencv-python\n",
    "!{sys.executable} -m pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbecbcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT PACKAGES\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "import os, zipfile, random, csv\n",
    "import seaborn as sns\n",
    "import pydicom as dcm\n",
    "from glob import glob\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# CUSTOM MODULES\n",
    "from eda import *\n",
    "from visualize import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd07fd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "DATA_DIR = 'data/'\n",
    "TRAIN_IMAGES = os.path.join(DATA_DIR + 'stage_2_train_images/')\n",
    "TEST_IMAGES = os.path.join(DATA_DIR + 'stage_2_test_images/')\n",
    "OUTPUT_DIR = 'output/'\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327206a4",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "Here as a part of EDA, we will:\n",
    "* Start with understanding of the data with a brief on train/test labels and respective class info\n",
    "* Look at the first five rows of both the csvs (train and test)\n",
    "* Identify how are classes and target distributed\n",
    "* Check the number of patients with 1, 2, ... bounding boxes\n",
    "* Read and extract metadata from dicom files\n",
    "* Perform analysis on some of the features from dicom files\n",
    "* Check some random images from the training dataset\n",
    "* Draw insights from the data at various stages of EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e86bcf8",
   "metadata": {},
   "source": [
    "### Reading CSVs\n",
    "* Images for the current stage in the `stage_2_train_images` and `stage_2_test_images`.\n",
    "* Training data: `stage_2_train_labels.csv`\n",
    "* `stage_2_detailed_class_info.csv` containing detailed information about the positive and negative classes in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e4aff36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ Reading Datasets (two csv files) ------------------------------\n",
      "Train Labels dataframe has 30227 rows and 6 columns\n",
      "Class info dataframe has 30227 rows and 2 columns\n",
      "Number of duplicates in patientID in train labels dataframe: 3543\n",
      "Number of duplicates in patientID in class info dataframe: 3543\n"
     ]
    }
   ],
   "source": [
    "print('--'*15, 'Reading Datasets (two csv files)', '--'*15)\n",
    "train_labels = pd.read_csv(DATA_DIR +'/stage_2_train_labels.csv/'+'stage_2_train_labels.csv')\n",
    "class_info = pd.read_csv(DATA_DIR +'/stage_2_detailed_class_info.csv/'+'stage_2_detailed_class_info.csv')\n",
    "\n",
    "print(f'Train Labels dataframe has {train_labels.shape[0]} rows and {train_labels.shape[1]} columns')\n",
    "print(f'Class info dataframe has {class_info.shape[0]} rows and {class_info.shape[1]} columns')\n",
    "print('Number of duplicates in patientID in train labels dataframe: {}'.format(len(train_labels) - (train_labels['patientId'].nunique())))\n",
    "print('Number of duplicates in patientID in class info dataframe: {}'.format(len(class_info) - (class_info['patientId'].nunique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecba2cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- First five rows of both dataframes (train_labels, class_info) --------------------\n",
      "Train labels dataframe:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientId</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0004cfab-14fd-4e49-80ba-63a80b6bddd6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00313ee0-9eaa-42f4-b0ab-c148ed3241cd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00322d4d-1c29-4943-afc9-b6754be640eb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003d8fa0-6bf1-40ed-b54c-ac657f8495c5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00436515-870c-4b36-a041-de91049b9ab4</td>\n",
       "      <td>264.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              patientId      x      y  width  height  Target\n",
       "0  0004cfab-14fd-4e49-80ba-63a80b6bddd6    NaN    NaN    NaN     NaN       0\n",
       "1  00313ee0-9eaa-42f4-b0ab-c148ed3241cd    NaN    NaN    NaN     NaN       0\n",
       "2  00322d4d-1c29-4943-afc9-b6754be640eb    NaN    NaN    NaN     NaN       0\n",
       "3  003d8fa0-6bf1-40ed-b54c-ac657f8495c5    NaN    NaN    NaN     NaN       0\n",
       "4  00436515-870c-4b36-a041-de91049b9ab4  264.0  152.0  213.0   379.0       1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class info dataframe:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientId</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0004cfab-14fd-4e49-80ba-63a80b6bddd6</td>\n",
       "      <td>No Lung Opacity / Not Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00313ee0-9eaa-42f4-b0ab-c148ed3241cd</td>\n",
       "      <td>No Lung Opacity / Not Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00322d4d-1c29-4943-afc9-b6754be640eb</td>\n",
       "      <td>No Lung Opacity / Not Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003d8fa0-6bf1-40ed-b54c-ac657f8495c5</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00436515-870c-4b36-a041-de91049b9ab4</td>\n",
       "      <td>Lung Opacity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              patientId                         class\n",
       "0  0004cfab-14fd-4e49-80ba-63a80b6bddd6  No Lung Opacity / Not Normal\n",
       "1  00313ee0-9eaa-42f4-b0ab-c148ed3241cd  No Lung Opacity / Not Normal\n",
       "2  00322d4d-1c29-4943-afc9-b6754be640eb  No Lung Opacity / Not Normal\n",
       "3  003d8fa0-6bf1-40ed-b54c-ac657f8495c5                        Normal\n",
       "4  00436515-870c-4b36-a041-de91049b9ab4                  Lung Opacity"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('--'*10, 'First five rows of both dataframes (train_labels, class_info)', '--'*10)\n",
    "print('Train labels dataframe:\\n'); display(train_labels.head())\n",
    "print('\\nClass info dataframe:\\n'); display(class_info.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32160c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of nulls in bounding boxes columns are equal to the 0s we've in Target column\n",
      "--------------------------------------------------------------------------------\n",
      "Checking nulls in bounding boxes columns: {'x': 20672, 'y': 20672, 'width': 20672, 'height': 20672}\n",
      "Checking value counts for the targets: {0: 20672, 1: 9555}\n"
     ]
    }
   ],
   "source": [
    "print('Numbers of nulls in bounding boxes columns are equal to the 0s we\\'ve in Target column'); print('--'*40)\n",
    "print('Checking nulls in bounding boxes columns: {}'.format(train_labels[['x', 'y', 'width', 'height']].isnull().sum().to_dict())) \n",
    "print('Checking value counts for the targets: {}'.format(train_labels['Target'].value_counts().to_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2ff023d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets check the distribution of `Target` and `class` column\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Lets check the distribution of `Target` and `class` column'); print('--'*40)\n",
    "fig = plt.figure(figsize = (10, 6))\n",
    "ax = fig.add_subplot(121)\n",
    "g = (train_labels['Target'].value_counts()\n",
    "    .plot(kind = 'pie', autopct = '%.0f%%', \n",
    "          labels = ['Negative', 'Pneumonia Evidence'], \n",
    "          colors = ['lightgray', 'brown'], \n",
    "          startangle = 90, \n",
    "          title = 'Distribution of Target', fontsize = 12)\n",
    "    .set_ylabel(''))\n",
    "ax = fig.add_subplot(122)\n",
    "g = (class_info['class'].value_counts().sort_index(ascending = False)\n",
    "    .plot(kind = 'pie', autopct = '%.0f%%', \n",
    "          colors = ['gainsboro', 'lightgray', 'brown'], \n",
    "          startangle = 90, title = 'Distribution of Class', \n",
    "          fontsize = 12)\n",
    "    .set_ylabel(''))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5bb3ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's group by patient IDs and check number of bounding boxes for each unique patient ID\n",
      "--------------------------------------------------------------------------------\n",
      "Number of unique patient IDs in the dataset: 26684\n",
      "\n",
      "Number of patientIDs per bboxes in the dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_patientIDs_per_boxes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_boxes</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 number_of_patientIDs_per_boxes\n",
       "number_of_boxes                                \n",
       "1                                         23286\n",
       "2                                          3266\n",
       "3                                           119\n",
       "4                                            13"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Let\\'s group by patient IDs and check number of bounding boxes for each unique patient ID');print('--'*40)\n",
    "bboxes = train_labels.groupby('patientId').size().to_frame('number_of_boxes').reset_index()\n",
    "train_labels = train_labels.merge(bboxes, on = 'patientId', how = 'left')\n",
    "print('Number of unique patient IDs in the dataset: {}'.format(len(bboxes)))\n",
    "print('\\nNumber of patientIDs per bboxes in the dataset')\n",
    "(bboxes.groupby('number_of_boxes')\n",
    ".size()\n",
    ".to_frame('number_of_patientIDs_per_boxes')\n",
    ".reset_index()\n",
    ".set_index('number_of_boxes')\n",
    ".sort_values(by = 'number_of_boxes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "735bcf56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's also check whether each patientId has only one type of class\n",
      "--------------------------------------------------------------------------------\n",
      "Yes, each patientId is associated with only 1 class\n",
      "Shape of the dataset after the merge: (30227, 8)\n"
     ]
    }
   ],
   "source": [
    "print('Let\\'s also check whether each patientId has only one type of class'); print('--'*40)\n",
    "print('Yes, each patientId is associated with only {} class'.format(class_info.groupby(['patientId'])['class'].nunique().max()))\n",
    "\n",
    "# Merge the two dataframes\n",
    "train_class = pd.concat([train_labels, class_info['class']], axis = 1)\n",
    "print('Shape of the dataset after the merge: {}'.format(train_class.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c34aed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientId</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>Target</th>\n",
       "      <th>number_of_boxes</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0004cfab-14fd-4e49-80ba-63a80b6bddd6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>No Lung Opacity / Not Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00313ee0-9eaa-42f4-b0ab-c148ed3241cd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>No Lung Opacity / Not Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00322d4d-1c29-4943-afc9-b6754be640eb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>No Lung Opacity / Not Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003d8fa0-6bf1-40ed-b54c-ac657f8495c5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00436515-870c-4b36-a041-de91049b9ab4</td>\n",
       "      <td>264.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Lung Opacity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              patientId      x      y  width  height  Target  \\\n",
       "0  0004cfab-14fd-4e49-80ba-63a80b6bddd6    NaN    NaN    NaN     NaN       0   \n",
       "1  00313ee0-9eaa-42f4-b0ab-c148ed3241cd    NaN    NaN    NaN     NaN       0   \n",
       "2  00322d4d-1c29-4943-afc9-b6754be640eb    NaN    NaN    NaN     NaN       0   \n",
       "3  003d8fa0-6bf1-40ed-b54c-ac657f8495c5    NaN    NaN    NaN     NaN       0   \n",
       "4  00436515-870c-4b36-a041-de91049b9ab4  264.0  152.0  213.0   379.0       1   \n",
       "\n",
       "   number_of_boxes                         class  \n",
       "0                1  No Lung Opacity / Not Normal  \n",
       "1                1  No Lung Opacity / Not Normal  \n",
       "2                1  No Lung Opacity / Not Normal  \n",
       "3                1                        Normal  \n",
       "4                2                  Lung Opacity  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_class.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7a2492",
   "metadata": {},
   "source": [
    "#### Observations from the CSVs\n",
    "Based on analysis above, some of the observations:\n",
    "\n",
    "* Training data is having a set of patientIds and bounding boxes. Bounding boxes are defined as follows: x, y, width and height.\n",
    "* There are multiple records for patients. Number of duplicates in patientID = 3,543.\n",
    "* There is also a binary target column i.e. Target indicating there was evidence of pneumonia or no definitive evidence of pneumonia.\n",
    "* Class label contains: No Lung Opacity/Not Normal, Normal and Lung Opacity.\n",
    "* Chest examinations with Target = 1 i.e. ones with evidence of Pneumonia are associated with Lung Opacity class.\n",
    "* Chest examinations with Target = 0 i.e. those with no definitive effidence of Pneumonia are either of Normal or No Lung Opacity / Not Normal class.\n",
    "* About 23,286 patientIds (~87% of them) provided have 1 bounding boxes while 13 patients have 4 bounding boxes!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9750ef61",
   "metadata": {},
   "source": [
    "### Reading Images\n",
    "Images provided are stored in DICOM (.dcm) format which is an international standard to transmit, store, retrieve, print, process, and display medical imaging information. Digital Imaging and Communications in Medicine (DICOM) makes medical imaging information interoperable. We will make use of pydicom package here to read the images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca68df5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset.file_meta -------------------------------\n",
      "(0002, 0000) File Meta Information Group Length  UL: 202\n",
      "(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n",
      "(0002, 0002) Media Storage SOP Class UID         UI: Secondary Capture Image Storage\n",
      "(0002, 0003) Media Storage SOP Instance UID      UI: 1.2.276.0.7230010.3.1.4.8323329.28530.1517874485.775526\n",
      "(0002, 0010) Transfer Syntax UID                 UI: JPEG Baseline (Process 1)\n",
      "(0002, 0012) Implementation Class UID            UI: 1.2.276.0.7230010.3.0.3.6.0\n",
      "(0002, 0013) Implementation Version Name         SH: 'OFFIS_DCMTK_360'\n",
      "-------------------------------------------------\n",
      "(0008, 0005) Specific Character Set              CS: 'ISO_IR 100'\n",
      "(0008, 0016) SOP Class UID                       UI: Secondary Capture Image Storage\n",
      "(0008, 0018) SOP Instance UID                    UI: 1.2.276.0.7230010.3.1.4.8323329.28530.1517874485.775526\n",
      "(0008, 0020) Study Date                          DA: '19010101'\n",
      "(0008, 0030) Study Time                          TM: '000000.00'\n",
      "(0008, 0050) Accession Number                    SH: ''\n",
      "(0008, 0060) Modality                            CS: 'CR'\n",
      "(0008, 0064) Conversion Type                     CS: 'WSD'\n",
      "(0008, 0090) Referring Physician's Name          PN: ''\n",
      "(0008, 103e) Series Description                  LO: 'view: PA'\n",
      "(0010, 0010) Patient's Name                      PN: '0004cfab-14fd-4e49-80ba-63a80b6bddd6'\n",
      "(0010, 0020) Patient ID                          LO: '0004cfab-14fd-4e49-80ba-63a80b6bddd6'\n",
      "(0010, 0030) Patient's Birth Date                DA: ''\n",
      "(0010, 0040) Patient's Sex                       CS: 'F'\n",
      "(0010, 1010) Patient's Age                       AS: '51'\n",
      "(0018, 0015) Body Part Examined                  CS: 'CHEST'\n",
      "(0018, 5101) View Position                       CS: 'PA'\n",
      "(0020, 000d) Study Instance UID                  UI: 1.2.276.0.7230010.3.1.2.8323329.28530.1517874485.775525\n",
      "(0020, 000e) Series Instance UID                 UI: 1.2.276.0.7230010.3.1.3.8323329.28530.1517874485.775524\n",
      "(0020, 0010) Study ID                            SH: ''\n",
      "(0020, 0011) Series Number                       IS: '1'\n",
      "(0020, 0013) Instance Number                     IS: '1'\n",
      "(0020, 0020) Patient Orientation                 CS: ''\n",
      "(0028, 0002) Samples per Pixel                   US: 1\n",
      "(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n",
      "(0028, 0010) Rows                                US: 1024\n",
      "(0028, 0011) Columns                             US: 1024\n",
      "(0028, 0030) Pixel Spacing                       DS: [0.14300000000000002, 0.14300000000000002]\n",
      "(0028, 0100) Bits Allocated                      US: 8\n",
      "(0028, 0101) Bits Stored                         US: 8\n",
      "(0028, 0102) High Bit                            US: 7\n",
      "(0028, 0103) Pixel Representation                US: 0\n",
      "(0028, 2110) Lossy Image Compression             CS: '01'\n",
      "(0028, 2114) Lossy Image Compression Method      CS: 'ISO_10918_1'\n",
      "(7fe0, 0010) Pixel Data                          OB: Array of 142006 elements\n"
     ]
    }
   ],
   "source": [
    "sample_patient_id = train_labels['patientId'][0]\n",
    "dcm_file = TRAIN_IMAGES + '{}.dcm'.format(sample_patient_id)\n",
    "dcm_data = dcm.read_file(dcm_file)\n",
    "\n",
    "print(dcm_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad077c4",
   "metadata": {},
   "source": [
    "#### Observations from dicom image files\n",
    "From the above sample we can see that dicom file contains some of the information that can be used for further analysis such as sex, age, body part examined (which should be mostly chest), view position and modality. Size of this image is 1024 x 1024 (rows x columns)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0333af",
   "metadata": {},
   "source": [
    "### Feature extraction from the dicom image files\n",
    "Above we identified some features from the dicom files that can explored/used, let's focus on the following analysis from the image files\n",
    "* To understand distribution of age for those with evidence of lung opacity and those with no definite evidence of lung opacity.\n",
    "* To understand distribution of male and female for those with evidence of lung opacity and those with no definite evidence of lung opacity\n",
    "* Explore different view positions in the dataset\n",
    "* Explore modallity\n",
    "\n",
    "To get the features from dicom image files, we will make use of function (`get_tags`) defined in (`eda`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b811392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read the training images file names and path\n",
      "--------------------------------------------------------------------------------\n",
      "Number of images in the training folder: 26684\n",
      "Columns in the training images dataframe: ['path', 'patientId']\n"
     ]
    }
   ],
   "source": [
    "print('Read the training images file names and path'); print('--'*40)\n",
    "images = pd.DataFrame({'path': glob(os.path.join(TRAIN_IMAGES, '*.dcm'))})\n",
    "images['patientId'] = images['path'].map(lambda x: os.path.splitext(os.path.basename(x))[0])\n",
    "print('Number of images in the training folder: {}'.format(images.shape[0]))\n",
    "print('Columns in the training images dataframe: {}'.format(list(images.columns)))\n",
    "assert images.shape[0] == len(list(set(train_class['patientId']))), 'Number of training images should be equal to the unique patientIds we have'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39529e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge path from the `images` dataframe with `train_class` dataframe\n",
      "--------------------------------------------------------------------------------\n",
      "Shape of the `train_class` dataframe after merge: (30227, 9)\n"
     ]
    }
   ],
   "source": [
    "print('Merge path from the `images` dataframe with `train_class` dataframe'); print('--'*40)\n",
    "train_class = train_class.merge(images, on = 'patientId', how = 'left')\n",
    "print('Shape of the `train_class` dataframe after merge: {}'.format(train_class.shape))\n",
    "del images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d58de04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get features such as ('PatientSex', 'PatientAge', 'BodyPartExamined', 'ViewPosition', 'Modality') from training images\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f0c06b5826442a792d338f1a3db3836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Get features such as {} from training images'.format(('PatientSex', 'PatientAge', 'BodyPartExamined', 'ViewPosition', 'Modality')))\n",
    "get_tags(train_class, TRAIN_IMAGES)\n",
    "\n",
    "print('Saving the feature engineered dataframe for future use'); print('--'*40)\n",
    "train_class.to_pickle('./output/train_feature_engineered.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5984465b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class = pd.read_pickle('./output/train_feature_engineered.pkl')\n",
    "train_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdb0356",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facfee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('As expected unique in `BodyPartExamined` is: {}'.format(train_class['BodyPartExamined'].unique()[0]))\n",
    "print('Unique in `Modality` is: {}'.format(train_class['Modality'].unique()[0])); print('--'*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa994a86",
   "metadata": {},
   "source": [
    "#### Understanding different View Positions\n",
    "As seen below, two View Positions that are in the training dataset are AP (Anterior/Posterior) and PA (Posterior/Anterior). These type of X-rays are mostly used to obtain the front-view. Apart from front-view, a lateral image is usually taken to complement the front-view.\n",
    "\n",
    "* **Posterior/Anterior (PA)**: In PA, X-Ray beam hits the posterior (back) part of the chest before the anterior (front) part. While obtaining the image patient is asked to stand with their chest against the film.\n",
    "* **Anterior/Posterior (AP)**: Attimes it's not possible for radiographers to acquire a PA chest X-ray. This is usually because the patient is too unwell to stand. AP projection images are of lower quality than PA images. Heart size is exaggerated (cardiothoracic ratio approximately 50%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8190bb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Get the distribution of `ViewPosition` overall and where Target = 1')\n",
    "print('Overall the distribution is almost equal for `ViewPosition` but where there\\'s a Pneumonia Evidence, `ViewPosition` is `AP`')\n",
    "print('AP: Anterior/Posterior, PA: Posterior/Anterior'); print('--'*40)\n",
    "fig = plt.figure(figsize = (10, 6))\n",
    "ax = fig.add_subplot(121)\n",
    "g = (train_class['ViewPosition'].value_counts()\n",
    "    .plot(kind = 'pie', autopct = '%.0f%%',  \n",
    "          startangle = 90,\n",
    "          title = 'Distribution of ViewPosition, Overall', \n",
    "          fontsize = 12)\n",
    "    .set_ylabel(''))\n",
    "ax = fig.add_subplot(122)\n",
    "g = (train_class.loc[train_class['Target'] == 1, 'ViewPosition']\n",
    "     .value_counts().sort_index(ascending = False)\n",
    "    .plot(kind = 'pie', autopct = '%.0f%%', \n",
    "          startangle = 90, counterclock = False, \n",
    "          title = 'Distribution of ViewPosition, Pneumonia Evidence', \n",
    "          fontsize = 12)\n",
    "    .set_ylabel(''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7f9bad",
   "metadata": {},
   "source": [
    "Exploring the bounding boxes for both view positions\n",
    "* Centers of the rectangle would be x+width/2 and y+height/2 as also described in the reference link [*(source)*](https://stackoverflow.com/questions/32471199/why-is-the-center-of-a-rectangle-xwidth-2-yheight-2-in-java).\n",
    "* We will make use of (`bboxes_scatter`) function in the (`eda`).\n",
    "Reference for these plots and function [*(source)*](https://www.kaggle.com/gpreda/rsna-pneumonia-detection-eda)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40db9e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Plot x and y centers of bounding boxes'); print('--'*40)\n",
    "# Creating a dataframe with columns for center of the rectangles\n",
    "bboxes = train_class[train_class['Target'] == 1]\n",
    "bboxes['xw'] = bboxes['x'] + bboxes['width'] / 2\n",
    "bboxes['yh'] = bboxes['y'] + bboxes['height'] / 2\n",
    "\n",
    "g = sns.jointplot(x = bboxes['xw'], y = bboxes['yh'], data = bboxes, \n",
    "                  kind = 'hex', alpha = 0.5, size = 8)\n",
    "plt.suptitle('Bounding Boxes Location, Pneumonia Evidence')\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top = 0.95)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932f4b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Exploring the bounding boxes centers for `ViewPositions` for random sample = 1000')\n",
    "\n",
    "df1 = bboxes[bboxes['ViewPosition'] == 'PA'].sample(1000)\n",
    "df2 = bboxes[bboxes['ViewPosition'] == 'AP'].sample(1000)\n",
    "bboxes_scatter(df1, df2, 'View Position = PA', 'View Position = AP')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48a120f",
   "metadata": {},
   "source": [
    "#### Observations: PatientAge & PatientSex\n",
    "Above we saw,\n",
    "* For `PatientAge` we saw the distribution for both overall and where there were evidence of Pneumonia. Used binning to check the count of age bins. Count was highest for age group 40-78 both overall and with Pneumonia Evidence. \n",
    "* Saw distribution of age for Male and Female with Pneumonia Evidence.\n",
    "* Dataset had more Males (57%-58%) than Females (42%-43%).\n",
    "\n",
    ">Only `PatientAge`, `PatientSex` and `ViewPosition` are useful features from metadata.\n",
    "\n",
    "Dropping the other features from `train_class` dataframe and save that as a pickle file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8cdcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class.drop(['BodyPartExamined', 'Modality'], inplace = True, axis = 1)\n",
    "train_class.to_pickle('./output/train_class_features.pkl')\n",
    "display(train_class.shape, train_class.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8924d98",
   "metadata": {},
   "source": [
    "### Check some random samples from training data\n",
    "Checking some random samples as below:\n",
    "* Different classes i.e. Normal, No Lung Opacity / Not Normal and Lung Opacity\n",
    "* Two view positions that we have in the dataset\n",
    "* For the one with Pneumonia Evidence and age = 92\n",
    "\n",
    "Now, we will make use of custom module (`eda`) and function (`plot_dicom_images`) already imported earlier to visualize the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99a7e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Checking sample for different classes')\n",
    "sample1 = train_class.loc[train_class['class'] == 'Normal'].iloc[0]\n",
    "sample2 = train_class.loc[train_class['class'] == 'No Lung Opacity / Not Normal'].iloc[0]\n",
    "sample3 = train_class.loc[train_class['class'] == 'Lung Opacity'].iloc[1]\n",
    "ds1 = dcm.dcmread(sample1['path'])\n",
    "ds2 = dcm.dcmread(sample2['path'])\n",
    "ds3 = dcm.dcmread(sample3['path'])\n",
    "\n",
    "f, ((ax1, ax2, ax3)) = plt.subplots(1, 3, figsize = (15, 8))\n",
    "ax1.imshow(ds1.pixel_array, cmap = plt.cm.bone)\n",
    "ax1.set_title('Class = Normal')\n",
    "ax1.axis('off')\n",
    "ax2.imshow(ds2.pixel_array, cmap = plt.cm.bone)\n",
    "ax2.set_title('Class = No Lung Opacity / Not Normal')\n",
    "ax2.axis('off')\n",
    "ax3.imshow(ds3.pixel_array, cmap = plt.cm.bone)\n",
    "ax3.set_title('Class = Lung Opacity')\n",
    "ax3.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a17846",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample4 = train_class.loc[(train_class['ViewPosition'] == 'AP')].iloc[0]\n",
    "sample5 = train_class.loc[(train_class['ViewPosition'] == 'PA')].iloc[0]\n",
    "ds4 = dcm.dcmread(sample4['path'])\n",
    "ds5 = dcm.dcmread(sample5['path'])\n",
    "\n",
    "f, ((ax1, ax2)) = plt.subplots(1, 2, figsize = (15, 8))\n",
    "ax1.imshow(ds4.pixel_array, cmap = plt.cm.bone)\n",
    "ax1.set_title('View Position = AP')\n",
    "ax1.axis('off')\n",
    "ax2.imshow(ds5.pixel_array, cmap = plt.cm.bone)\n",
    "ax2.set_title('View Position = PA')\n",
    "ax2.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b288f0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is a part of custom module imported earlier (`eda`)\n",
    "plot_dicom_images(data = train_class.loc[(train_class['Target'] == 1)].sample(9), \n",
    "                  df = train_class, img_path = TRAIN_IMAGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ced1f2",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b980efe0",
   "metadata": {},
   "source": [
    "### Split into Train & Valid\n",
    "* Splitting the list of training images in train and valid images\n",
    "* Random shuffle the list of training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8afa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Create training and valid sets. Contains list of filenames'); print('--'*40)\n",
    "image_fns = os.listdir(TRAIN_IMAGES)\n",
    "random.shuffle(image_fns)\n",
    "val_size = round(len(image_fns)/10)\n",
    "train_size = len(image_fns) - val_size\n",
    "\n",
    "image_fns_train = image_fns[:train_size]\n",
    "image_fns_val = image_fns[train_size: (train_size + val_size)]\n",
    "\n",
    "print('Number of training samples: {}'.format(train_size))\n",
    "print('Number of valid samples: {}'.format(val_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ad70d5",
   "metadata": {},
   "source": [
    "### Load Pneumonia Evidence\n",
    "[*(reference)*](https://www.kaggle.com/jonnedtc/cnn-segmentation-connected-components)\n",
    "\n",
    "* Dictionary contains pairs per row.\n",
    "* If there are multiple pneumonia evidence for a patient then the dictionary would contain multiple list tagged to a patient id key. If there's no pneumonia evidence it will have an empty list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a74517",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Load pneumonia evidence dictionary from `stage_2_train_labels.csv`'); print('--'*40)\n",
    "pneumonia_evidence = get_pneumonia_evidence(filename = 'stage_2_train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c75823b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(pneumonia_evidence.keys())[0], list(pneumonia_evidence.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390b3d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Plot Masks generated using `generator` function, randomly'); print('--'*40)\n",
    "print('GROUND TRUTH', '--'*25)\n",
    "plot_masks(train_class, TRAIN_IMAGES, image_fns, pneumonia_evidence)\n",
    "plot_masks(train_class, TRAIN_IMAGES, image_fns, pneumonia_evidence)\n",
    "plot_masks(train_class, TRAIN_IMAGES, image_fns, pneumonia_evidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6809659",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
